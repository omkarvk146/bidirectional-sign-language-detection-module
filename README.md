This project aims to bridge the communication gap between hearing and speech-impaired individuals and non-signers using AI/ML. It supports bidirectional translation:
Speech/Text ➡️ Sign Language (Speech-to-Sign Module)
Sign Gestures ➡️ Text/Speech (Gesture-to-Text Module)
Built with Python, OpenCV, MediaPipe, and TensorFlow, the system leverages real-time hand gesture recognition and text-to-sign animation to provide a seamless, user-friendly interface for inclusive communication.

